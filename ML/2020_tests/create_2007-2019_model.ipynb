{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('mlenv': conda)"
  },
  "interpreter": {
   "hash": "fb187ceb99e597fc4fb087033f2a56d4997f1306a985d00c1ac5ca0a4e888195"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Import data from s3.amazonaws"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_url = 'https://s3.amazonaws.com/parkerhiggins-nba-draft-bucket/MBB_StatsAndDraft.csv'\n",
    "data_2007_2020 = 'https://s3.amazonaws.com/parkerhiggins-nba-draft-bucket/07-20_MBB_StatsAndDraft.csv'\n",
    "data_2007_2019 = 'https://s3.amazonaws.com/parkerhiggins-nba-draft-bucket/07-19_MBB_StatsAndDraft.csv'\n",
    "\n",
    "raw_df = pd.read_csv(data_2007_2019)"
   ]
  },
  {
   "source": [
    "## Preprocessing: Remove non-numerical columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = raw_df.dtypes[raw_df.dtypes != 'object'].index.tolist()\n",
    "\n",
    "numerical_df = raw_df[numerical_cols]\n",
    "numerical_df.index = raw_df['#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         #  gp   mpg  fgm   fga    FG%  3PM  3PA    3P%  ftm  ...  orb  drb  \\\n",
       "#                                                             ...             \n",
       "16      16  33  30.0  9.0  13.2  0.680  0.7  2.2  0.338  3.9  ...  3.5  5.4   \n",
       "7        7  33  36.6  8.0  16.1  0.499  1.7  4.8  0.363  6.7  ...  1.2  4.5   \n",
       "576    576  32  34.0  4.2   9.1  0.459  0.8  2.8  0.307  3.5  ...  1.7  4.8   \n",
       "1177  1177  33  19.9  3.2   6.5  0.488  0.6  1.7  0.382  2.2  ...  1.2  2.4   \n",
       "264    264  38  32.5  5.4  10.4  0.520  1.2  2.8  0.438  3.2  ...  1.4  3.7   \n",
       "...    ...  ..   ...  ...   ...    ...  ...  ...    ...  ...  ...  ...  ...   \n",
       "309    309  29  32.8  5.4  13.3  0.405  2.0  6.3  0.310  2.4  ...  0.9  5.1   \n",
       "555    555  29  31.2  4.4   9.9  0.443  2.1  5.3  0.396  2.0  ...  0.9  5.4   \n",
       "135    135  29  31.0  5.8  13.1  0.441  1.9  5.2  0.371  3.7  ...  0.7  5.6   \n",
       "766    766  32  25.8  4.6   8.0  0.576  0.0  0.1  0.000  2.2  ...  2.0  4.6   \n",
       "1878  1878  32  17.4  2.4   4.5  0.531  0.0  0.1  0.000  1.0  ...  1.4  1.7   \n",
       "\n",
       "      rpg   apg  spg  bpg   ppg  season_year    pk  draft_year  \n",
       "#                                                               \n",
       "16    8.9   2.1  2.1  1.8  22.6         2019   1.0      2019.0  \n",
       "7     5.7  10.0  1.8  0.8  24.5         2019   2.0      2019.0  \n",
       "576   6.5   6.3  0.9  0.4  12.7         2018   2.0      2019.0  \n",
       "1177  3.5   1.1  0.6  0.4   9.2         2018   4.0      2019.0  \n",
       "264   5.1   2.0  0.6  0.6  15.2         2019   4.0      2019.0  \n",
       "...   ...   ...  ...  ...   ...          ...   ...         ...  \n",
       "309   6.0   3.6  0.9  0.7  15.1         2018  58.0      2019.0  \n",
       "555   6.3   2.7  0.7  1.1  12.9         2017  58.0      2019.0  \n",
       "135   6.3   3.6  0.9  1.3  17.1         2019  58.0      2019.0  \n",
       "766   6.7   0.4  0.5  1.0  11.4         2018  59.0      2019.0  \n",
       "1878  3.1   0.2  0.4  0.8   5.8         2017  59.0      2019.0  \n",
       "\n",
       "[112 rows x 24 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>gp</th>\n      <th>mpg</th>\n      <th>fgm</th>\n      <th>fga</th>\n      <th>FG%</th>\n      <th>3PM</th>\n      <th>3PA</th>\n      <th>3P%</th>\n      <th>ftm</th>\n      <th>...</th>\n      <th>orb</th>\n      <th>drb</th>\n      <th>rpg</th>\n      <th>apg</th>\n      <th>spg</th>\n      <th>bpg</th>\n      <th>ppg</th>\n      <th>season_year</th>\n      <th>pk</th>\n      <th>draft_year</th>\n    </tr>\n    <tr>\n      <th>#</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>33</td>\n      <td>30.0</td>\n      <td>9.0</td>\n      <td>13.2</td>\n      <td>0.680</td>\n      <td>0.7</td>\n      <td>2.2</td>\n      <td>0.338</td>\n      <td>3.9</td>\n      <td>...</td>\n      <td>3.5</td>\n      <td>5.4</td>\n      <td>8.9</td>\n      <td>2.1</td>\n      <td>2.1</td>\n      <td>1.8</td>\n      <td>22.6</td>\n      <td>2019</td>\n      <td>1.0</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>33</td>\n      <td>36.6</td>\n      <td>8.0</td>\n      <td>16.1</td>\n      <td>0.499</td>\n      <td>1.7</td>\n      <td>4.8</td>\n      <td>0.363</td>\n      <td>6.7</td>\n      <td>...</td>\n      <td>1.2</td>\n      <td>4.5</td>\n      <td>5.7</td>\n      <td>10.0</td>\n      <td>1.8</td>\n      <td>0.8</td>\n      <td>24.5</td>\n      <td>2019</td>\n      <td>2.0</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>576</th>\n      <td>576</td>\n      <td>32</td>\n      <td>34.0</td>\n      <td>4.2</td>\n      <td>9.1</td>\n      <td>0.459</td>\n      <td>0.8</td>\n      <td>2.8</td>\n      <td>0.307</td>\n      <td>3.5</td>\n      <td>...</td>\n      <td>1.7</td>\n      <td>4.8</td>\n      <td>6.5</td>\n      <td>6.3</td>\n      <td>0.9</td>\n      <td>0.4</td>\n      <td>12.7</td>\n      <td>2018</td>\n      <td>2.0</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>1177</th>\n      <td>1177</td>\n      <td>33</td>\n      <td>19.9</td>\n      <td>3.2</td>\n      <td>6.5</td>\n      <td>0.488</td>\n      <td>0.6</td>\n      <td>1.7</td>\n      <td>0.382</td>\n      <td>2.2</td>\n      <td>...</td>\n      <td>1.2</td>\n      <td>2.4</td>\n      <td>3.5</td>\n      <td>1.1</td>\n      <td>0.6</td>\n      <td>0.4</td>\n      <td>9.2</td>\n      <td>2018</td>\n      <td>4.0</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>264</td>\n      <td>38</td>\n      <td>32.5</td>\n      <td>5.4</td>\n      <td>10.4</td>\n      <td>0.520</td>\n      <td>1.2</td>\n      <td>2.8</td>\n      <td>0.438</td>\n      <td>3.2</td>\n      <td>...</td>\n      <td>1.4</td>\n      <td>3.7</td>\n      <td>5.1</td>\n      <td>2.0</td>\n      <td>0.6</td>\n      <td>0.6</td>\n      <td>15.2</td>\n      <td>2019</td>\n      <td>4.0</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>309</th>\n      <td>309</td>\n      <td>29</td>\n      <td>32.8</td>\n      <td>5.4</td>\n      <td>13.3</td>\n      <td>0.405</td>\n      <td>2.0</td>\n      <td>6.3</td>\n      <td>0.310</td>\n      <td>2.4</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>5.1</td>\n      <td>6.0</td>\n      <td>3.6</td>\n      <td>0.9</td>\n      <td>0.7</td>\n      <td>15.1</td>\n      <td>2018</td>\n      <td>58.0</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>555</th>\n      <td>555</td>\n      <td>29</td>\n      <td>31.2</td>\n      <td>4.4</td>\n      <td>9.9</td>\n      <td>0.443</td>\n      <td>2.1</td>\n      <td>5.3</td>\n      <td>0.396</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>5.4</td>\n      <td>6.3</td>\n      <td>2.7</td>\n      <td>0.7</td>\n      <td>1.1</td>\n      <td>12.9</td>\n      <td>2017</td>\n      <td>58.0</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>135</td>\n      <td>29</td>\n      <td>31.0</td>\n      <td>5.8</td>\n      <td>13.1</td>\n      <td>0.441</td>\n      <td>1.9</td>\n      <td>5.2</td>\n      <td>0.371</td>\n      <td>3.7</td>\n      <td>...</td>\n      <td>0.7</td>\n      <td>5.6</td>\n      <td>6.3</td>\n      <td>3.6</td>\n      <td>0.9</td>\n      <td>1.3</td>\n      <td>17.1</td>\n      <td>2019</td>\n      <td>58.0</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>766</td>\n      <td>32</td>\n      <td>25.8</td>\n      <td>4.6</td>\n      <td>8.0</td>\n      <td>0.576</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>0.000</td>\n      <td>2.2</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>4.6</td>\n      <td>6.7</td>\n      <td>0.4</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>11.4</td>\n      <td>2018</td>\n      <td>59.0</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>1878</th>\n      <td>1878</td>\n      <td>32</td>\n      <td>17.4</td>\n      <td>2.4</td>\n      <td>4.5</td>\n      <td>0.531</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>0.000</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.4</td>\n      <td>1.7</td>\n      <td>3.1</td>\n      <td>0.2</td>\n      <td>0.4</td>\n      <td>0.8</td>\n      <td>5.8</td>\n      <td>2017</td>\n      <td>59.0</td>\n      <td>2019.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>112 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "numerical_df[numerical_df['draft_year'] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "numerical_df['draft_status'] = (numerical_df['season_year']==numerical_df['draft_year']).astype(bool)"
   ]
  },
  {
   "source": [
    "## Preprocessing: Select common individual basketball statistics to use as features in the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['#', 'gp', 'mpg', 'fgm', 'fga', 'FG%', '3PM', '3PA', '3P%', 'ftm',\n",
       "       'fta', 'FT%', 'tov', 'pf', 'orb', 'drb', 'rpg', 'apg', 'spg', 'bpg',\n",
       "       'ppg', 'season_year', 'pk', 'draft_year', 'draft_status'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "numerical_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = ['ppg','mpg','rpg','apg','spg','gp','tov','draft_status']\n",
    "selected_features = ['ppg','rpg','apg','spg','tov','draft_status','FG%','3P%','FT%']\n",
    "data_df = numerical_df[selected_features]\n",
    "\n",
    "# X = numerical_df.drop(columns=['draft_status', 'season_year','draft_year','pk','#','pf'])\n",
    "X = data_df.drop(columns=['draft_status'])\n",
    "y = data_df['draft_status']"
   ]
  },
  {
   "source": [
    "## Preprocessing: Use SMOTEENN to oversample drafted players and undersample undrafted players"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteenn = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = smoteenn.fit_resample(X,y)"
   ]
  },
  {
   "source": [
    "## Preprocessing: Test Random Undersampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ros = RandomUnderSampler(random_state=1)\n",
    "# X_resampled, y_resampled = ros.fit_resample(X,y)"
   ]
  },
  {
   "source": [
    "## Preprocessing: Split into training and test datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled,random_state=1,test_size=0.05)"
   ]
  },
  {
   "source": [
    "## Preprocessing: Scale data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "46666"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# X_train = X_scaler.transform(X_train)\n",
    "# X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "# Random Forest Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9884318766066839 \n\n[[1037   20]\n [   7 1270]] \n\n              precision    recall  f1-score   support\n\n       False       0.99      0.98      0.99      1057\n        True       0.98      0.99      0.99      1277\n\n    accuracy                           0.99      2334\n   macro avg       0.99      0.99      0.99      2334\nweighted avg       0.99      0.99      0.99      2334\n \n\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,random_state=1,)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "rf_acc_score = accuracy_score(y_test,rf_pred)\n",
    "rf_matrix = confusion_matrix(y_test,rf_pred)\n",
    "rf_results = pd.DataFrame({\"Prediction\": rf_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "rf_report = classification_report(y_test,rf_pred,zero_division=True)\n",
    "\n",
    "print(rf_acc_score,'\\n')\n",
    "print(rf_matrix,'\\n')\n",
    "print(rf_report,'\\n')\n",
    "\n",
    "model_filename = 'rf_2007_2019.sav'\n",
    "pickle.dump(rf, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Logistic Regression Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8564695801199658 \n\n[[ 883  174]\n [ 161 1116]] \n\n              precision    recall  f1-score   support\n\n       False       0.85      0.84      0.84      1057\n        True       0.87      0.87      0.87      1277\n\n    accuracy                           0.86      2334\n   macro avg       0.86      0.85      0.86      2334\nweighted avg       0.86      0.86      0.86      2334\n \n\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs',random_state=1, max_iter=1000)\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "lr_acc_score = accuracy_score(y_test,lr_pred)\n",
    "lr_matrix = confusion_matrix(y_test,lr_pred)\n",
    "lr_results = pd.DataFrame({\"Prediction\": lr_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "lr_report = classification_report(y_test,lr_pred,zero_division=True)\n",
    "\n",
    "print(lr_acc_score,'\\n')\n",
    "print(lr_matrix,'\\n')\n",
    "print(lr_report,'\\n')\n",
    "\n",
    "model_filename = 'lr_2007_2019.sav'\n",
    "pickle.dump(lr, open(model_filename, 'wb'))"
   ]
  },
  {
   "source": [
    "# Support Vector Machines (SVM) Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8586118251928021 \n\n[[ 883  174]\n [ 156 1121]] \n\n              precision    recall  f1-score   support\n\n       False       0.85      0.84      0.84      1057\n        True       0.87      0.88      0.87      1277\n\n    accuracy                           0.86      2334\n   macro avg       0.86      0.86      0.86      2334\nweighted avg       0.86      0.86      0.86      2334\n \n\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm.SVC(kernel='linear',probability=True)\n",
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "svm_acc_score = accuracy_score(y_test,svm_pred)\n",
    "svm_matrix = confusion_matrix(y_test,svm_pred)\n",
    "svm_results = pd.DataFrame({\"Prediction\": svm_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "svm_report = classification_report(y_test,svm_pred,zero_division=True)\n",
    "\n",
    "print(svm_acc_score,'\\n')\n",
    "print(svm_matrix,'\\n')\n",
    "print(svm_report,'\\n')\n",
    "\n",
    "model_filename = 'svm_2007_2019.sav'\n",
    "pickle.dump(svm_model, open(model_filename, 'wb'))"
   ]
  },
  {
   "source": [
    "# Gradient Boosting Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "learning_rate=0.05; training: 0.8872372101416584\n",
      "learning_rate=0.05; validation: 0.8851756640959726\n",
      "learning_rate=0.1; training: 0.9167644139673373\n",
      "learning_rate=0.1; validation: 0.9155955441302485\n",
      "learning_rate=0.25; training: 0.9723224758639357\n",
      "learning_rate=0.25; validation: 0.9708654670094259\n",
      "learning_rate=0.5; training: 0.9870522421726969\n",
      "learning_rate=0.5; validation: 0.9841473864610112\n",
      "learning_rate=0.75; training: 0.9894432915275647\n",
      "learning_rate=0.75; validation: 0.9862896315338475\n",
      "learning_rate=1; training: 0.9912929712171795\n",
      "learning_rate=1; validation: 0.987146529562982\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05,0.1,0.25,0.5,0.75,1]\n",
    "\n",
    "for rate in learning_rates:\n",
    "    classifier = GradientBoostingClassifier(n_estimators=100,learning_rate=rate,random_state=1)\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    print(f'learning_rate={rate}; training: {classifier.score(X_train,y_train)}')\n",
    "    print(f'learning_rate={rate}; validation: {classifier.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9880034275921166 \n\n[[1048    9]\n [  19 1258]] \n\n              precision    recall  f1-score   support\n\n       False       0.98      0.99      0.99      1057\n        True       0.99      0.99      0.99      1277\n\n    accuracy                           0.99      2334\n   macro avg       0.99      0.99      0.99      2334\nweighted avg       0.99      0.99      0.99      2334\n \n\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=1000,learning_rate=1,random_state=1)\n",
    "gb.fit(X_train,y_train)\n",
    "\n",
    "gb_pred = gb.predict(X_test)\n",
    "\n",
    "gb_acc_score = accuracy_score(y_test,gb_pred)\n",
    "gb_matrix = confusion_matrix(y_test,gb_pred)\n",
    "gb_results = pd.DataFrame({\"Prediction\": gb_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "gb_report = classification_report(y_test,gb_pred,zero_division=True)\n",
    "\n",
    "print(gb_acc_score,'\\n')\n",
    "print(gb_matrix,'\\n')\n",
    "print(gb_report,'\\n')\n",
    "\n",
    "model_filename = 'gb_2007_2019.sav'\n",
    "pickle.dump(gb, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0fb187ceb99e597fc4fb087033f2a56d4997f1306a985d00c1ac5ca0a4e888195",
   "display_name": "Python 3.7.9 64-bit ('mlenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "source": [
    "## Import data from s3.amazonaws"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_url = 'https://s3.amazonaws.com/parkerhiggins-nba-draft-bucket/MBB_StatsAndDraft.csv'\n",
    "data_2007_2020 = 'https://s3.amazonaws.com/parkerhiggins-nba-draft-bucket/07-20_MBB_StatsAndDraft.csv'\n",
    "data_2007_2019 = 'https://s3.amazonaws.com/parkerhiggins-nba-draft-bucket/07-19_MBB_StatsAndDraft.csv'\n",
    "\n",
    "raw_df = pd.read_csv(data_2007_2020)"
   ]
  },
  {
   "source": [
    "## Preprocessing: Remove non-numerical columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = raw_df.dtypes[raw_df.dtypes != 'object'].index.tolist()\n",
    "\n",
    "numerical_df = raw_df[numerical_cols]\n",
    "numerical_df.index = raw_df['#']"
   ]
  },
  {
   "source": [
    "## Preprocessing: Select common individual basketball statistics to use as features in the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['ppg','mpg','rpg','apg','spg','gp','tov','pk']\n",
    "data_df = numerical_df[selected_features]\n",
    "\n",
    "X = data_df.drop(columns=['pk'])\n",
    "y = data_df['pk'].apply(lambda x: 1 if x <= 60 else 2)"
   ]
  },
  {
   "source": [
    "## Preprocessing: Use SMOTEENN to oversample drafted players and undersample undrafted players"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteenn = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = smoteenn.fit_resample(X,y)"
   ]
  },
  {
   "source": [
    "## Preprocessing: Split into training and test datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled,random_state=1)"
   ]
  },
  {
   "source": [
    "## Preprocessing: Scale data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "# Random Forest Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9714138552665464 \n\n[[6445   90]\n [ 243 4871]] \n\n              precision    recall  f1-score   support\n\n           1       0.96      0.99      0.97      6535\n           2       0.98      0.95      0.97      5114\n\n    accuracy                           0.97     11649\n   macro avg       0.97      0.97      0.97     11649\nweighted avg       0.97      0.97      0.97     11649\n \n\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=120,random_state=1)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "rf_acc_score = accuracy_score(y_test,rf_pred)\n",
    "rf_matrix = confusion_matrix(y_test,rf_pred)\n",
    "rf_results = pd.DataFrame({\"Prediction\": rf_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "rf_report = classification_report(y_test,rf_pred,zero_division=True)\n",
    "\n",
    "print(rf_acc_score,'\\n')\n",
    "print(rf_matrix,'\\n')\n",
    "print(rf_report,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_player_stats = {'ppg': 19.2, 'mpg': 29.9, 'rpg': 3.8,\n",
    "                     'apg': 3.6, 'spg': 0.8, 'gp': 33, 'tov': 0.4}\n",
    "print()"
   ]
  },
  {
   "source": [
    "# Logistic Regression Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8026440037771483 \n\n[[5372 1163]\n [1136 3978]] \n\n              precision    recall  f1-score   support\n\n           1       0.83      0.82      0.82      6535\n           2       0.77      0.78      0.78      5114\n\n    accuracy                           0.80     11649\n   macro avg       0.80      0.80      0.80     11649\nweighted avg       0.80      0.80      0.80     11649\n \n\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver='lbfgs',random_state=1, max_iter=1000)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "lr_pred = classifier.predict(X_test)\n",
    "\n",
    "lr_acc_score = accuracy_score(y_test,lr_pred)\n",
    "lr_matrix = confusion_matrix(y_test,lr_pred)\n",
    "lr_results = pd.DataFrame({\"Prediction\": lr_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "lr_report = classification_report(y_test,lr_pred,zero_division=True)\n",
    "\n",
    "print(lr_acc_score,'\\n')\n",
    "print(lr_matrix,'\\n')\n",
    "print(lr_report,'\\n')"
   ]
  },
  {
   "source": [
    "# Support Vector Machines (SVM) Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8026440037771483 \n\n[[5331 1204]\n [1095 4019]] \n\n              precision    recall  f1-score   support\n\n           1       0.83      0.82      0.82      6535\n           2       0.77      0.79      0.78      5114\n\n    accuracy                           0.80     11649\n   macro avg       0.80      0.80      0.80     11649\nweighted avg       0.80      0.80      0.80     11649\n \n\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "svm_acc_score = accuracy_score(y_test,svm_pred)\n",
    "svm_matrix = confusion_matrix(y_test,svm_pred)\n",
    "svm_results = pd.DataFrame({\"Prediction\": svm_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "svm_report = classification_report(y_test,svm_pred,zero_division=True)\n",
    "\n",
    "print(svm_acc_score,'\\n')\n",
    "print(svm_matrix,'\\n')\n",
    "print(svm_report,'\\n')"
   ]
  },
  {
   "source": [
    "# Gradient Boosting Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "learning_rate=0.05; training: 0.8057343978023864\n",
      "learning_rate=0.05; validation: 0.8091681689415401\n",
      "learning_rate=0.1; training: 0.8150341946375941\n",
      "learning_rate=0.1; validation: 0.8174092196755086\n",
      "learning_rate=0.25; training: 0.85034480785189\n",
      "learning_rate=0.25; validation: 0.8483990042063696\n",
      "learning_rate=0.5; training: 0.8874581509142415\n",
      "learning_rate=0.5; validation: 0.881878272813117\n",
      "learning_rate=0.75; training: 0.9330128480270123\n",
      "learning_rate=0.75; validation: 0.924113657824706\n",
      "learning_rate=1; training: 0.9415686611154033\n",
      "learning_rate=1; validation: 0.9341574384067302\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05,0.1,0.25,0.5,0.75,1]\n",
    "\n",
    "for rate in learning_rates:\n",
    "    classifier = GradientBoostingClassifier(n_estimators=20,learning_rate=rate,random_state=1)\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    print(f'learning_rate={rate}; training: {classifier.score(X_train,y_train)}')\n",
    "    print(f'learning_rate={rate}; validation: {classifier.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9341574384067302 \n\n[[6129  406]\n [ 361 4753]] \n\n              precision    recall  f1-score   support\n\n           1       0.94      0.94      0.94      6535\n           2       0.92      0.93      0.93      5114\n\n    accuracy                           0.93     11649\n   macro avg       0.93      0.93      0.93     11649\nweighted avg       0.93      0.93      0.93     11649\n \n\n"
     ]
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier(n_estimators=20,learning_rate=1,random_state=1)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "gb_pred = classifier.predict(X_test)\n",
    "\n",
    "gb_acc_score = accuracy_score(y_test,gb_pred)\n",
    "gb_matrix = confusion_matrix(y_test,gb_pred)\n",
    "gb_results = pd.DataFrame({\"Prediction\": gb_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "gb_report = classification_report(y_test,gb_pred,zero_division=True)\n",
    "\n",
    "print(gb_acc_score,'\\n')\n",
    "print(gb_matrix,'\\n')\n",
    "print(gb_report,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}